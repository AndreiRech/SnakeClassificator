{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9da7df93-47fa-4f33-9097-20ac02564ed6",
   "metadata": {},
   "source": [
    "# Configurações Iniciais\n",
    "\n",
    "    - Importando bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23482328-85a9-41da-bb7d-6f56d150ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ad61d-fcc6-4288-a2b1-940f3c3780d3",
   "metadata": {},
   "source": [
    "    - Definindo a seed\n",
    "    - Setando o device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6649b46b-beac-491d-83e7-cfd892a93874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYHTONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff585868-816a-4e02-b9ac-142eb8c36722",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Definindo o Dataset\n",
    "    - Definindo as imagens\n",
    "    - Realizando a normalização\n",
    "    - Dividindo entre treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150406e5-1f50-442c-bcb6-c9a439ed2ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (256,256)\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize(img_size), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e7c1c-888d-4810-964f-30caf0067c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '.'\n",
    "print(os.listdir(dataset_dir))\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_dir, transform=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799551d2-05f7-4bc4-86ce-3e905897808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f99770-2a8c-4975-a829-17708fb4c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716c7827-9b8f-42b0-b876-06359587a5d4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Definindo Funções\n",
    "\n",
    "    - Validação\n",
    "    - Treino\n",
    "    - Acurácia\n",
    "    - Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e05d37-de98-445e-84f0-9a26fae8fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs,labels)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666b3a4-bf36-4056-be2c-326a28416636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, testloader, optimizer, criterion, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for data in tqdm(trainloader):\n",
    "            images, labels = data\n",
    "            model.zero_grad()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        val_loss = validation(model, testloader, criterion)\n",
    "        print(f'Epoch: {epoch+1} | Loss: {running_loss/len(trainloader)} | Val Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ac3f6c-4191-41eb-bfff-a578d91b6655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, loader):\n",
    "    model.eval()\n",
    "    corrected = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            corrected += (predicted == labels).sum().item()\n",
    "    return corrected * 100 // total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d69da-0db1-4645-8286-bcb67f63d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(model, loader):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros((2,2))\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "            for i in range(labels.size(0)):\n",
    "                confusion_matrix[labels[i].item()][predicted[i].item()] += 1\n",
    "    ax = sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g', xticklabels=['Coral Falsa', 'Coral Verdadeira'], yticklabels=['Coral Falsa', 'Coral Verdadeira'])\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Label')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736e269-5c2b-46ac-9928-b265189bfcb2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Treinando o Modelo\n",
    "\n",
    "    - Utilizando a resnet\n",
    "    - Congelar pesos das camadas\n",
    "    - Treinar com o dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4805f9f7-21c9-41f9-898d-fba8036b25b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet50(weights = torchvision.models.ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6d0033-c77e-4805-bb9b-b49049a08255",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.fc = nn.Linear(2048,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74301cd-8b36-4ea7-bdbf-a4508bc0a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, params in resnet.named_parameters():\n",
    "    if name not in ('fc.weight', 'fc.bias'):\n",
    "        params.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a171fef9-9c8b-4d87-95f4-2f45bc93c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86e1df2-e70b-4b04-95aa-142742200918",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(resnet, train_loader, test_loader, optimizer, criterion, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f71cafc-5d38-450b-8651-44b33a174a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'A rede atinge: {accuracy(resnet, test_loader)}% de acurácia')\n",
    "conf_mat = confusion_matrix(resnet, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213b5892-0703-4414-aed0-01c1cbbe547f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Comparando os Modelos\n",
    "\n",
    "    - Primeiro nós precisamos fazer os outros modelos né kk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b931a0-a4a3-40f8-8525-b0fff4549e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image):\n",
    "    prediction = model(torch.unsqueeze(image, 0).to(device))\n",
    "    result = torch.argmax(prediction)\n",
    "    return 'Coral Verdadeira' if result == 0 else 'Coral Falsa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e203f851-3c6c-46ac-b4a0-352c0f9d8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 20\n",
    "image = test[image_index][0]\n",
    "label = 'Coral Falsa' if test[image_index][1] else 'Coral Verdadeira'\n",
    "imshow(image)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a1b489-9778-4b9d-b307-a0bbe2341223",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Real Label: {label}')\n",
    "print(f'Resnet Prediction: {predict(resnet, image)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9db90c-d73d-4643-b6ef-fca5bab3062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "x = Image.open('teste.jpg').convert('RGB')\n",
    "x = transformations(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48617149-6202-44e2-986d-34d46068530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Resnet Prediction: {predict(resnet, x)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
