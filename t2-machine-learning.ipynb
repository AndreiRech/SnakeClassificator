{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9da7df93-47fa-4f33-9097-20ac02564ed6",
   "metadata": {},
   "source": [
    "## Configurações Iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23482328-85a9-41da-bb7d-6f56d150ab8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms, datasets\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import os\n",
    "\n",
    "def set_seed(seed=1234):\n",
    "\n",
    "    random.seed(seed)\n",
    "    os.environ['PYHTONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8045d7-fbdc-416d-abba-770e846f541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d76d094-1f35-465e-aa04-9578e8fcfdff",
   "metadata": {},
   "source": [
    "## O que é o PyTorch?\n",
    "- biblioteca de aprendizado profundo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace32c89-a78b-4349-93e2-3749b16e87fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor(1)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d6fc7e-99c2-4646-812a-6dd377e14446",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor(55)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53e821-06cf-4465-8184-ddf612220407",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6842203-b033-4742-a592-cc2f523c90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[1,2,3], [4,5,6]])\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81866e1e-91ba-48c9-9618-4ff671091d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "matx1 = torch.randn([3,3])\n",
    "matx2 = torch.randn([3,3])\n",
    "print(matx1)\n",
    "print()\n",
    "print(matx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f637e2e-eb3c-440e-8467-816fb94c1b58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matx1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmatx1\u001b[49m \u001b[38;5;241m+\u001b[39m matx2\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matx1' is not defined"
     ]
    }
   ],
   "source": [
    "matx1 + matx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "643629d7-afcd-4dab-bdf9-979b36c18640",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matx1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmatx1\u001b[49m \u001b[38;5;241m*\u001b[39m matx2\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matx1' is not defined"
     ]
    }
   ],
   "source": [
    "matx1 * matx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be56b6d5-2e0c-48fb-898c-83167b059d09",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mmm(matx1, matx2)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.mm(matx1, matx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c89399-d637-40fa-b417-17a585b13326",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = x**2\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c091b20-a98d-4f0b-a4da-1ae37c2788a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = x+2\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b6b82-0494-4949-85dc-c0b608072442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix multiplication of a big matrix and compare time between gpu and cpu without timeit\n",
    "x = torch.randn([1000,1000])\n",
    "y = torch.randn([1000,1000])\n",
    "%timeit torch.mm(x,y)\n",
    "\n",
    "x = x.to('cuda')\n",
    "y = y.to('cuda')\n",
    "%timeit torch.mm(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23a8a9d-f10d-4b1d-9fac-372f3ddc352d",
   "metadata": {},
   "source": [
    "## Preparando o Dataset\n",
    "- dataset de gatos e cachorros que o professor usou\n",
    "- devemos substituir por outro dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e7c1c-888d-4810-964f-30caf0067c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset\n",
    "! pip install gdown\n",
    "! gdown --id 17zbLsM4n1QQJutNncsAaSRFj4uJVELak\n",
    "!unzip /content/dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fc0067-349a-48ee-8fe9-c64b9235b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (256,256)\n",
    "transformations = transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()])\n",
    "\n",
    "train = datasets.ImageFolder('./train',transform=transformations)\n",
    "test= datasets.ImageFolder('./test', transform=transformations)\n",
    "trainloader = DataLoader(train, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91663929-312d-4f79-93d9-3b774f2f2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    plt.figure(figsize=(20,8))\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images = next(dataiter)\n",
    "imshow(torchvision.utils.make_grid(images[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982bb8e6-3a17-4ef1-b95b-52017e970839",
   "metadata": {},
   "source": [
    "## Criando uma MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d8c4a1-abdc-4b6a-a983-2ef0a0d65ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            # input = (256,256,3)\n",
    "            nn.Flatten(), # (196608)\n",
    "            nn.Linear(256*256*3, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64,2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5891b07d-37f2-4510-87a7-15a3af4f853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs,labels)\n",
    "            val_loss +=loss\n",
    "    return val_loss/len(loader)\n",
    "\n",
    "def train(model, trainloader, testloader, optimizer, criterion, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for data in tqdm(trainloader):\n",
    "            images, labels = data\n",
    "            model.zero_grad()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        val_loss = validation(model, testloader, criterion)\n",
    "        print(f'Epoch: {epoch+1} | Loss: {running_loss/len(trainloader)} | Val Loss: {val_loss}')\n",
    "\n",
    "def accuracy(model, loader):\n",
    "    model.eval()\n",
    "    corrected = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            corrected += (predicted == labels).sum().item()\n",
    "    return corrected * 100 // total\n",
    "\n",
    "def confusion_matrix(model, loader):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros((2,2))\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "            for i in range(labels.size(0)):\n",
    "                confusion_matrix[labels[i].item()][predicted[i].item()] += 1\n",
    "    ax = sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g', xticklabels=['Gato', 'Cachorro'], yticklabels=['Gato', 'Cachorro'])\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Label')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5247fd6-d6b6-4ee9-8ebe-0c898f6b00a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(mlp.parameters(), lr=0.001)\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79277bae-8b71-48e4-bba4-7dbb487b4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(mlp, trainloader, testloader, optimizer, criterion, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ad46d-0005-4c8a-aa70-f8164238df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'A rede atinge: {accuracy(mlp, testloader)}% de acurácia')\n",
    "conf_mat = confusion_matrix(mlp, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d35f4b-d142-4f33-9c9e-66f996637c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNeuralNetwork, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            #input = (256,256,3)\n",
    "            nn.Conv2d(3,16, kernel_size=3, stride=1, padding=1), # (256,256,16)\n",
    "            nn.ReLU(inplace=True), # (256,256,16)\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2), # (128,128,16)\n",
    "            nn.Conv2d(16,8, kernel_size=3, stride=1, padding=1), # (128,128,8)\n",
    "            nn.ReLU(inplace=True), # (128,128,8)\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2), # (64,64,8)\n",
    "            nn.Flatten(), # (1024)\n",
    "            nn.Linear(64*64*8,256), # (256)\n",
    "            nn.ReLU(inplace=True),  # (256)\n",
    "            nn.Linear(256,2) # (2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ab1103-e639-4284-8a67-ef42f10c23a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = ConvolutionalNeuralNetwork().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.001)\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a747a-defe-4095-a131-9edae6e5bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'A rede atinge: {accuracy(cnn, testloader)}% de acurácia')\n",
    "conf_mat = confusion_matrix(cnn, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736e269-5c2b-46ac-9928-b265189bfcb2",
   "metadata": {},
   "source": [
    "## Trasfer Learning\n",
    "- arquitetura para reconhecimento de imagens e classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4805f9f7-21c9-41f9-898d-fba8036b25b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet50(weights = torchvision.models.ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d496b06d-a2eb-4ca3-a338-2b122c323ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6d0033-c77e-4805-bb9b-b49049a08255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# substituímos a última camada da rede para resolver o nosso problema de classificação\n",
    "resnet.fc = nn.Linear(2048,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32568afb-9f79-43aa-b0a8-6b970e1d423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74301cd-8b36-4ea7-bdbf-a4508bc0a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"congelamos os pesos das camadas, exceto a última\"\n",
    "for name, params in resnet.named_parameters():\n",
    "    if name not in ('fc.weight', 'fc.bias'):\n",
    "        params.requires_grad = False\n",
    "# for name, params in resnet.named_parameters():\n",
    "#     print(name, params.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a171fef9-9c8b-4d87-95f4-2f45bc93c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86e1df2-e70b-4b04-95aa-142742200918",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(resnet, trainloader, testloader, optimizer, criterion, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f71cafc-5d38-450b-8651-44b33a174a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'A rede atinge: {accuracy(resnet, testloader)}% de acurácia')\n",
    "conf_mat = confusion_matrix(resnet, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213b5892-0703-4414-aed0-01c1cbbe547f",
   "metadata": {},
   "source": [
    "## Comparando os Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b931a0-a4a3-40f8-8525-b0fff4549e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image):\n",
    "    prediction = model(torch.unsqueeze(image, 0).to(device))\n",
    "    result = torch.argmax(prediction)\n",
    "    return 'Cat' if result == 0 else 'Dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e203f851-3c6c-46ac-b4a0-352c0f9d8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 20\n",
    "image = test[image_index][0]\n",
    "label = 'Dog' if test[image_index][1] else 'Cat'\n",
    "imshow(image)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a1b489-9778-4b9d-b307-a0bbe2341223",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Real Label: {label}')\n",
    "print(f'MLP Prediction: {predict(mlp, image)}')\n",
    "print(f'CNN Prediction: {predict(cnn, image)}')\n",
    "print(f'Resnet Prediction: {predict(resnet, image)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9db90c-d73d-4643-b6ef-fca5bab3062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "x = Image.open('caramelo.jpg').convert('RGB')\n",
    "x = transformations(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48617149-6202-44e2-986d-34d46068530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MLP Prediction: {predict(mlp, x)}')\n",
    "print(f'CNN Prediction: {predict(cnn, x)}')\n",
    "print(f'Resnet Prediction: {predict(resnet, x)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
